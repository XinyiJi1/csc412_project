{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFAPmMtTs03S"
      },
      "source": [
        "# CSC294-082 Project (transformer generating part)\n",
        "#### Author: Xinyi Ji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K_OafJ9Fkb27"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "import pandas as pd\n",
        "import torch.utils.data as data\n",
        "import pickle as pkl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBlVlG67sxeK"
      },
      "source": [
        "### Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pbdfthD1XHFv"
      },
      "outputs": [],
      "source": [
        "checkpt = torch.load('transformer_model_new.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "t1h0B6VpsMz2",
        "outputId": "b6cb5438-fb6b-4948-ae52-71bb354e1cc6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-28739841-dad9-47dd-a1da-5391b7a2b50c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>1240</th>\n",
              "      <th>1241</th>\n",
              "      <th>1242</th>\n",
              "      <th>1243</th>\n",
              "      <th>1244</th>\n",
              "      <th>1245</th>\n",
              "      <th>1246</th>\n",
              "      <th>1247</th>\n",
              "      <th>1248</th>\n",
              "      <th>1249</th>\n",
              "      <th>1250</th>\n",
              "      <th>1251</th>\n",
              "      <th>1252</th>\n",
              "      <th>1253</th>\n",
              "      <th>1254</th>\n",
              "      <th>1255</th>\n",
              "      <th>1256</th>\n",
              "      <th>1257</th>\n",
              "      <th>1258</th>\n",
              "      <th>1259</th>\n",
              "      <th>1260</th>\n",
              "      <th>1261</th>\n",
              "      <th>1262</th>\n",
              "      <th>1263</th>\n",
              "      <th>1264</th>\n",
              "      <th>1265</th>\n",
              "      <th>1266</th>\n",
              "      <th>1267</th>\n",
              "      <th>1268</th>\n",
              "      <th>1269</th>\n",
              "      <th>1270</th>\n",
              "      <th>1271</th>\n",
              "      <th>1272</th>\n",
              "      <th>1273</th>\n",
              "      <th>1274</th>\n",
              "      <th>1275</th>\n",
              "      <th>1276</th>\n",
              "      <th>1277</th>\n",
              "      <th>1278</th>\n",
              "      <th>1279</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>4392</td>\n",
              "      <td>7418</td>\n",
              "      <td>3153</td>\n",
              "      <td>3115</td>\n",
              "      <td>1443</td>\n",
              "      <td>369</td>\n",
              "      <td>802</td>\n",
              "      <td>3078</td>\n",
              "      <td>3029</td>\n",
              "      <td>4466</td>\n",
              "      <td>1327</td>\n",
              "      <td>2226</td>\n",
              "      <td>6839</td>\n",
              "      <td>8106</td>\n",
              "      <td>6384</td>\n",
              "      <td>2773</td>\n",
              "      <td>907</td>\n",
              "      <td>3067</td>\n",
              "      <td>6770</td>\n",
              "      <td>7190</td>\n",
              "      <td>2796</td>\n",
              "      <td>3741</td>\n",
              "      <td>5594</td>\n",
              "      <td>5173</td>\n",
              "      <td>1965</td>\n",
              "      <td>1459</td>\n",
              "      <td>3544</td>\n",
              "      <td>5079</td>\n",
              "      <td>1076</td>\n",
              "      <td>7592</td>\n",
              "      <td>2686</td>\n",
              "      <td>35</td>\n",
              "      <td>684</td>\n",
              "      <td>6332</td>\n",
              "      <td>2248</td>\n",
              "      <td>2410</td>\n",
              "      <td>6438</td>\n",
              "      <td>5232</td>\n",
              "      <td>4340</td>\n",
              "      <td>3732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>5348</td>\n",
              "      <td>3623</td>\n",
              "      <td>4011</td>\n",
              "      <td>8135</td>\n",
              "      <td>3104</td>\n",
              "      <td>5908</td>\n",
              "      <td>3940</td>\n",
              "      <td>7692</td>\n",
              "      <td>4905</td>\n",
              "      <td>7557</td>\n",
              "      <td>5127</td>\n",
              "      <td>5896</td>\n",
              "      <td>7110</td>\n",
              "      <td>7207</td>\n",
              "      <td>443</td>\n",
              "      <td>3162</td>\n",
              "      <td>5485</td>\n",
              "      <td>3460</td>\n",
              "      <td>487</td>\n",
              "      <td>4431</td>\n",
              "      <td>39</td>\n",
              "      <td>1414</td>\n",
              "      <td>1121</td>\n",
              "      <td>2716</td>\n",
              "      <td>1830</td>\n",
              "      <td>5256</td>\n",
              "      <td>6160</td>\n",
              "      <td>5740</td>\n",
              "      <td>5740</td>\n",
              "      <td>1378</td>\n",
              "      <td>165</td>\n",
              "      <td>6997</td>\n",
              "      <td>513</td>\n",
              "      <td>5888</td>\n",
              "      <td>715</td>\n",
              "      <td>7221</td>\n",
              "      <td>1477</td>\n",
              "      <td>1718</td>\n",
              "      <td>6809</td>\n",
              "      <td>7624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2412</td>\n",
              "      <td>5539</td>\n",
              "      <td>4720</td>\n",
              "      <td>3537</td>\n",
              "      <td>8118</td>\n",
              "      <td>8013</td>\n",
              "      <td>5092</td>\n",
              "      <td>6220</td>\n",
              "      <td>986</td>\n",
              "      <td>98</td>\n",
              "      <td>6977</td>\n",
              "      <td>6682</td>\n",
              "      <td>6029</td>\n",
              "      <td>4191</td>\n",
              "      <td>4636</td>\n",
              "      <td>7381</td>\n",
              "      <td>4720</td>\n",
              "      <td>5117</td>\n",
              "      <td>7024</td>\n",
              "      <td>7541</td>\n",
              "      <td>7557</td>\n",
              "      <td>2826</td>\n",
              "      <td>4921</td>\n",
              "      <td>672</td>\n",
              "      <td>7247</td>\n",
              "      <td>2132</td>\n",
              "      <td>2389</td>\n",
              "      <td>7232</td>\n",
              "      <td>6865</td>\n",
              "      <td>2706</td>\n",
              "      <td>7549</td>\n",
              "      <td>7539</td>\n",
              "      <td>7562</td>\n",
              "      <td>2655</td>\n",
              "      <td>6077</td>\n",
              "      <td>1851</td>\n",
              "      <td>5687</td>\n",
              "      <td>3320</td>\n",
              "      <td>6326</td>\n",
              "      <td>3814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3433</td>\n",
              "      <td>1107</td>\n",
              "      <td>4013</td>\n",
              "      <td>5119</td>\n",
              "      <td>3028</td>\n",
              "      <td>5468</td>\n",
              "      <td>6997</td>\n",
              "      <td>2793</td>\n",
              "      <td>4569</td>\n",
              "      <td>8160</td>\n",
              "      <td>7131</td>\n",
              "      <td>7123</td>\n",
              "      <td>4735</td>\n",
              "      <td>348</td>\n",
              "      <td>5997</td>\n",
              "      <td>4521</td>\n",
              "      <td>3740</td>\n",
              "      <td>4264</td>\n",
              "      <td>3901</td>\n",
              "      <td>4742</td>\n",
              "      <td>6441</td>\n",
              "      <td>2285</td>\n",
              "      <td>1343</td>\n",
              "      <td>3924</td>\n",
              "      <td>421</td>\n",
              "      <td>7011</td>\n",
              "      <td>423</td>\n",
              "      <td>2764</td>\n",
              "      <td>3477</td>\n",
              "      <td>421</td>\n",
              "      <td>5608</td>\n",
              "      <td>6583</td>\n",
              "      <td>3044</td>\n",
              "      <td>5886</td>\n",
              "      <td>3821</td>\n",
              "      <td>684</td>\n",
              "      <td>117</td>\n",
              "      <td>4036</td>\n",
              "      <td>5671</td>\n",
              "      <td>5066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2654</td>\n",
              "      <td>7520</td>\n",
              "      <td>5405</td>\n",
              "      <td>568</td>\n",
              "      <td>635</td>\n",
              "      <td>6776</td>\n",
              "      <td>3161</td>\n",
              "      <td>7582</td>\n",
              "      <td>410</td>\n",
              "      <td>5107</td>\n",
              "      <td>7229</td>\n",
              "      <td>4605</td>\n",
              "      <td>5914</td>\n",
              "      <td>6660</td>\n",
              "      <td>4809</td>\n",
              "      <td>2411</td>\n",
              "      <td>2684</td>\n",
              "      <td>4236</td>\n",
              "      <td>7716</td>\n",
              "      <td>4150</td>\n",
              "      <td>2817</td>\n",
              "      <td>2496</td>\n",
              "      <td>1789</td>\n",
              "      <td>7018</td>\n",
              "      <td>4355</td>\n",
              "      <td>6600</td>\n",
              "      <td>906</td>\n",
              "      <td>3773</td>\n",
              "      <td>1824</td>\n",
              "      <td>4698</td>\n",
              "      <td>7239</td>\n",
              "      <td>1732</td>\n",
              "      <td>2817</td>\n",
              "      <td>6614</td>\n",
              "      <td>6321</td>\n",
              "      <td>164</td>\n",
              "      <td>5731</td>\n",
              "      <td>4232</td>\n",
              "      <td>5537</td>\n",
              "      <td>7389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3370</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>49</td>\n",
              "      <td>7143</td>\n",
              "      <td>61</td>\n",
              "      <td>7304</td>\n",
              "      <td>5364</td>\n",
              "      <td>2705</td>\n",
              "      <td>2975</td>\n",
              "      <td>1105</td>\n",
              "      <td>1613</td>\n",
              "      <td>459</td>\n",
              "      <td>8111</td>\n",
              "      <td>3401</td>\n",
              "      <td>5390</td>\n",
              "      <td>5652</td>\n",
              "      <td>1035</td>\n",
              "      <td>5322</td>\n",
              "      <td>2854</td>\n",
              "      <td>2765</td>\n",
              "      <td>7188</td>\n",
              "      <td>7415</td>\n",
              "      <td>6735</td>\n",
              "      <td>4255</td>\n",
              "      <td>3541</td>\n",
              "      <td>4007</td>\n",
              "      <td>5232</td>\n",
              "      <td>4194</td>\n",
              "      <td>4796</td>\n",
              "      <td>1824</td>\n",
              "      <td>6082</td>\n",
              "      <td>4011</td>\n",
              "      <td>4353</td>\n",
              "      <td>3528</td>\n",
              "      <td>3576</td>\n",
              "      <td>7910</td>\n",
              "      <td>255</td>\n",
              "      <td>4291</td>\n",
              "      <td>8135</td>\n",
              "      <td>3997</td>\n",
              "      <td>1062</td>\n",
              "      <td>5628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3371</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>4017</td>\n",
              "      <td>785</td>\n",
              "      <td>3158</td>\n",
              "      <td>255</td>\n",
              "      <td>6559</td>\n",
              "      <td>4262</td>\n",
              "      <td>3231</td>\n",
              "      <td>7795</td>\n",
              "      <td>773</td>\n",
              "      <td>8002</td>\n",
              "      <td>4584</td>\n",
              "      <td>746</td>\n",
              "      <td>5970</td>\n",
              "      <td>1846</td>\n",
              "      <td>5780</td>\n",
              "      <td>4786</td>\n",
              "      <td>5210</td>\n",
              "      <td>5734</td>\n",
              "      <td>6936</td>\n",
              "      <td>1520</td>\n",
              "      <td>2672</td>\n",
              "      <td>6135</td>\n",
              "      <td>601</td>\n",
              "      <td>3288</td>\n",
              "      <td>8091</td>\n",
              "      <td>2152</td>\n",
              "      <td>3077</td>\n",
              "      <td>1319</td>\n",
              "      <td>686</td>\n",
              "      <td>4670</td>\n",
              "      <td>7059</td>\n",
              "      <td>2894</td>\n",
              "      <td>48</td>\n",
              "      <td>2950</td>\n",
              "      <td>5364</td>\n",
              "      <td>255</td>\n",
              "      <td>3083</td>\n",
              "      <td>4451</td>\n",
              "      <td>3590</td>\n",
              "      <td>6800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3372</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>4005</td>\n",
              "      <td>1958</td>\n",
              "      <td>1430</td>\n",
              "      <td>2070</td>\n",
              "      <td>907</td>\n",
              "      <td>2986</td>\n",
              "      <td>5906</td>\n",
              "      <td>6198</td>\n",
              "      <td>7523</td>\n",
              "      <td>7858</td>\n",
              "      <td>6931</td>\n",
              "      <td>1263</td>\n",
              "      <td>5120</td>\n",
              "      <td>5993</td>\n",
              "      <td>3571</td>\n",
              "      <td>304</td>\n",
              "      <td>1941</td>\n",
              "      <td>6580</td>\n",
              "      <td>2115</td>\n",
              "      <td>2639</td>\n",
              "      <td>1822</td>\n",
              "      <td>7989</td>\n",
              "      <td>7491</td>\n",
              "      <td>2650</td>\n",
              "      <td>4575</td>\n",
              "      <td>951</td>\n",
              "      <td>6082</td>\n",
              "      <td>6148</td>\n",
              "      <td>2136</td>\n",
              "      <td>3528</td>\n",
              "      <td>2496</td>\n",
              "      <td>5415</td>\n",
              "      <td>4005</td>\n",
              "      <td>4824</td>\n",
              "      <td>4147</td>\n",
              "      <td>6639</td>\n",
              "      <td>8025</td>\n",
              "      <td>2533</td>\n",
              "      <td>6422</td>\n",
              "      <td>4835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3373</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>8023</td>\n",
              "      <td>3851</td>\n",
              "      <td>7190</td>\n",
              "      <td>4383</td>\n",
              "      <td>7484</td>\n",
              "      <td>3959</td>\n",
              "      <td>7230</td>\n",
              "      <td>4698</td>\n",
              "      <td>5275</td>\n",
              "      <td>2553</td>\n",
              "      <td>2260</td>\n",
              "      <td>3490</td>\n",
              "      <td>4237</td>\n",
              "      <td>7798</td>\n",
              "      <td>6307</td>\n",
              "      <td>2513</td>\n",
              "      <td>2777</td>\n",
              "      <td>4233</td>\n",
              "      <td>3684</td>\n",
              "      <td>6950</td>\n",
              "      <td>6141</td>\n",
              "      <td>4478</td>\n",
              "      <td>7545</td>\n",
              "      <td>916</td>\n",
              "      <td>7520</td>\n",
              "      <td>3577</td>\n",
              "      <td>5048</td>\n",
              "      <td>1075</td>\n",
              "      <td>1204</td>\n",
              "      <td>450</td>\n",
              "      <td>5997</td>\n",
              "      <td>2557</td>\n",
              "      <td>7755</td>\n",
              "      <td>649</td>\n",
              "      <td>3635</td>\n",
              "      <td>3433</td>\n",
              "      <td>1944</td>\n",
              "      <td>6135</td>\n",
              "      <td>4950</td>\n",
              "      <td>4312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3374</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1067</td>\n",
              "      <td>154</td>\n",
              "      <td>3494</td>\n",
              "      <td>7451</td>\n",
              "      <td>6195</td>\n",
              "      <td>2398</td>\n",
              "      <td>7064</td>\n",
              "      <td>261</td>\n",
              "      <td>4712</td>\n",
              "      <td>2995</td>\n",
              "      <td>5408</td>\n",
              "      <td>8188</td>\n",
              "      <td>1293</td>\n",
              "      <td>517</td>\n",
              "      <td>4449</td>\n",
              "      <td>6456</td>\n",
              "      <td>3043</td>\n",
              "      <td>263</td>\n",
              "      <td>2861</td>\n",
              "      <td>214</td>\n",
              "      <td>2732</td>\n",
              "      <td>3755</td>\n",
              "      <td>6858</td>\n",
              "      <td>2672</td>\n",
              "      <td>1579</td>\n",
              "      <td>5129</td>\n",
              "      <td>2684</td>\n",
              "      <td>1443</td>\n",
              "      <td>540</td>\n",
              "      <td>1969</td>\n",
              "      <td>4364</td>\n",
              "      <td>7461</td>\n",
              "      <td>6215</td>\n",
              "      <td>6744</td>\n",
              "      <td>2896</td>\n",
              "      <td>4089</td>\n",
              "      <td>3288</td>\n",
              "      <td>5975</td>\n",
              "      <td>932</td>\n",
              "      <td>568</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3375 rows × 1280 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28739841-dad9-47dd-a1da-5391b7a2b50c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-28739841-dad9-47dd-a1da-5391b7a2b50c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-28739841-dad9-47dd-a1da-5391b7a2b50c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      0     1     2     3     4     5     ...  1274  1275  1276  1277  1278  1279\n",
              "0        0     0     0    10     4     0  ...  2248  2410  6438  5232  4340  3732\n",
              "1        0     0     0    12     1     8  ...   715  7221  1477  1718  6809  7624\n",
              "2        0     0     0    10    11     2  ...  6077  1851  5687  3320  6326  3814\n",
              "3        0     0     0    10    15     0  ...  3821   684   117  4036  5671  5066\n",
              "4        0     0     0    10     0     9  ...  6321   164  5731  4232  5537  7389\n",
              "...    ...   ...   ...   ...   ...   ...  ...   ...   ...   ...   ...   ...   ...\n",
              "3370     0     0     0     9     8     0  ...   255  4291  8135  3997  1062  5628\n",
              "3371     0     0     0     9     0     8  ...  5364   255  3083  4451  3590  6800\n",
              "3372     0     0     0    10     0    10  ...  4147  6639  8025  2533  6422  4835\n",
              "3373     0     0     0     9    10     0  ...  3635  3433  1944  6135  4950  4312\n",
              "3374     0     0     0     9     0     0  ...  2896  4089  3288  5975   932   568\n",
              "\n",
              "[3375 rows x 1280 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df = pd.read_csv('transformer_data_new.csv')\n",
        "df.columns = range(256+1024)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-Ct3ewR7sSp5"
      },
      "outputs": [],
      "source": [
        "txt_col = range(256)\n",
        "img_col = range(256,1024+256)\n",
        "df_txt = df[txt_col]\n",
        "df_img = df[img_col]\n",
        "txt_array = df_txt.values\n",
        "img_array = df_img.values\n",
        "all_data = df.values\n",
        "all_data = torch.from_numpy(all_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj3rPShfsXPP",
        "outputId": "a0b67d4a-6c38-42d8-c86b-2258db319e45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3375"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "all_data.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1olWY-tVscwr"
      },
      "outputs": [],
      "source": [
        "def split_train_test(data, train_fraq=0.8): \n",
        " n_samples = data.shape[0] \n",
        " data_train = data[:int(n_samples * train_fraq)] \n",
        " data_test = data[int(n_samples * train_fraq):] \n",
        " return data_train, data_test "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TZM_qLymshav"
      },
      "outputs": [],
      "source": [
        "all_data = split_train_test(all_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_data[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3ciFA68-G3p",
        "outputId": "bb2e8f6d-5863-495a-8b71-c2d06510f59b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2700, 1280])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVOgX2Gjsj_5",
        "outputId": "119c1aad-6dde-485d-d845-04297ddbec48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([675, 1280])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "all_data[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fqeQv3XDsnWq"
      },
      "outputs": [],
      "source": [
        "train_X = all_data[0][:, :256]\n",
        "train_y = all_data[0][:,256:]\n",
        "test_X =  all_data[1][:, :256]\n",
        "test_y = all_data[1][:,256:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "k0AZLbn9svWi"
      },
      "outputs": [],
      "source": [
        "with open('./train_img_token1.pkl','rb') as f: first_token = pkl.load(f)\n",
        "with open('./train_img_token1_test.pkl','rb') as f: first_token_test = pkl.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QSeBm4wXtQSj"
      },
      "outputs": [],
      "source": [
        "start_token = torch.tensor(first_token) # [2700]\n",
        "start_token_test = torch.tensor(first_token_test) # [675]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9dwDSla0WhN",
        "outputId": "ed4f3c3d-fc08-4cab-8c53-a04c40367df6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([675])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "start_token_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_token_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5yYcg4SF3KS",
        "outputId": "522e15fa-d0e5-46e1-de89-5406ad3e523b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([675])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "X3aehQLUsqY6"
      },
      "outputs": [],
      "source": [
        "def dataloader(dataset, **kwargs): \n",
        "  if 'shuffle' not in kwargs: \n",
        "    kwargs['shuffle'] = False \n",
        "  if 'drop_last' not in kwargs: \n",
        "    kwargs['drop_last'] = True \n",
        "  if 'batch_size' not in kwargs: \n",
        "    kwargs['batch_size'] = 32 \n",
        "  if 'num_workers' not in kwargs: \n",
        "    kwargs['num_workers'] = 8 \n",
        "    kwargs['batch_size'] = min(kwargs['batch_size'], len(dataset)) \n",
        "  return data.DataLoader(dataset, **kwargs) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEJflPC8stg4",
        "outputId": "48d742ee-03c1-4537-cb10-ed5de479978b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "# Train data is a tensor\n",
        "batch_size = 10\n",
        "num_workers = 8\n",
        "train_dataset = data.TensorDataset(train_X, train_y, start_token) \n",
        "test_dataset = data.TensorDataset(test_X, test_y, start_token_test) \n",
        "train_dataloader = dataloader(train_dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True) \n",
        "test_dataloader = dataloader(test_dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bNT5vnrW0lvS"
      },
      "outputs": [],
      "source": [
        "# for batch_idx, (x, y, z) in enumerate(train_dataloader):\n",
        "#   print(x)\n",
        "#   print(x.shape)\n",
        "#   print(y)\n",
        "#   print(y.shape)\n",
        "#   print(z)\n",
        "#   print(z.shape)\n",
        "#   print(\"----\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPHnzR0u0LBP"
      },
      "source": [
        "###  Transformer Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UYp5KqMEZ7Nw"
      },
      "outputs": [],
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, embed_size, heads):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.heads = heads\n",
        "        self.head_dim = embed_size // heads\n",
        "\n",
        "        assert (\n",
        "            self.head_dim * heads == embed_size\n",
        "        ), \"Embedding size needs to be divisible by heads\"\n",
        "\n",
        "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "        self.fc_out = nn.Linear(heads * self.head_dim, embed_size)\n",
        "\n",
        "    def forward(self, values, keys, query, mask):\n",
        "        # Get number of training examples\n",
        "        N = query.shape[0]\n",
        "\n",
        "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
        "\n",
        "        # Split the embedding into self.heads different pieces\n",
        "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
        "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
        "        query = query.reshape(N, query_len, self.heads, self.head_dim)\n",
        "\n",
        "        values = self.values(values)  # (N, value_len, heads, head_dim)\n",
        "        keys = self.keys(keys)  # (N, key_len, heads, head_dim)\n",
        "        queries = self.queries(query)  # (N, query_len, heads, heads_dim)\n",
        "\n",
        "        # Einsum does matrix mult. for query*keys for each training example\n",
        "        # with every other training example, don't be confused by einsum\n",
        "        # it's just how I like doing matrix multiplication & bmm\n",
        "\n",
        "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
        "        # queries shape: (N, query_len, heads, heads_dim),\n",
        "        # keys shape: (N, key_len, heads, heads_dim)\n",
        "        # energy: (N, heads, query_len, key_len)\n",
        "\n",
        "        # Mask padded indices so their weights become 0\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
        "\n",
        "        # Normalize energy values similarly to seq2seq + attention\n",
        "        # so that they sum to 1. Also divide by scaling factor for\n",
        "        # better stability\n",
        "        attention = torch.softmax(energy / (self.embed_size ** (1 / 2)), dim=3)\n",
        "        # attention shape: (N, heads, query_len, key_len)\n",
        "\n",
        "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
        "            N, query_len, self.heads * self.head_dim\n",
        "        )\n",
        "        # attention shape: (N, heads, query_len, key_len)\n",
        "        # values shape: (N, value_len, heads, heads_dim)\n",
        "        # out after matrix multiply: (N, query_len, heads, head_dim), then\n",
        "        # we reshape and flatten the last two dimensions.\n",
        "\n",
        "        out = self.fc_out(out)\n",
        "        # Linear layer doesn't modify the shape, final shape will be\n",
        "        # (N, query_len, embed_size)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CCr_LQk2aDyx"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.attention = SelfAttention(embed_size, heads)\n",
        "        self.norm1 = nn.LayerNorm(embed_size)\n",
        "        self.norm2 = nn.LayerNorm(embed_size)\n",
        "\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(embed_size, forward_expansion * embed_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(forward_expansion * embed_size, embed_size),\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, value, key, query, mask):\n",
        "        attention = self.attention(value, key, query, mask)\n",
        "\n",
        "        # Add skip connection, run through normalization and finally dropout\n",
        "        x = self.dropout(self.norm1(attention + query))\n",
        "        forward = self.feed_forward(x)\n",
        "        out = self.dropout(self.norm2(forward + x))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "s9fPAnrVaIHp"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        src_vocab_size,\n",
        "        embed_size,\n",
        "        num_layers,\n",
        "        heads,\n",
        "        device,\n",
        "        forward_expansion,\n",
        "        dropout,\n",
        "        max_length = 256,\n",
        "    ):\n",
        "\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.device = device\n",
        "        self.word_embedding = nn.Embedding(src_vocab_size, embed_size)\n",
        "        self.position_embedding = nn.Embedding(max_length, embed_size)\n",
        "\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                TransformerBlock(\n",
        "                    embed_size,\n",
        "                    heads,\n",
        "                    dropout=dropout,\n",
        "                    forward_expansion=forward_expansion,\n",
        "                )\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        N, seq_length = x.shape\n",
        "        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
        "        out = self.dropout(\n",
        "            (self.word_embedding(x) + self.position_embedding(positions))\n",
        "        )\n",
        "\n",
        "        # In the Encoder the query, key, value are all the same, it's in the\n",
        "        # decoder this will change. This might look a bit odd in this case.\n",
        "        for layer in self.layers:\n",
        "            out = layer(out, out, out, mask)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "opgOtpa8aN2u"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, embed_size, heads, forward_expansion, dropout, device):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.norm = nn.LayerNorm(embed_size)\n",
        "        self.attention = SelfAttention(embed_size, heads=heads)\n",
        "        self.transformer_block = TransformerBlock(\n",
        "            embed_size, heads, dropout, forward_expansion\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, value, key, src_mask, trg_mask):\n",
        "        attention = self.attention(x, x, x, trg_mask)\n",
        "        query = self.dropout(self.norm(attention + x))\n",
        "        out = self.transformer_block(value, key, query, src_mask)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "qj0zctuvaT1e"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        trg_vocab_size,\n",
        "        embed_size,\n",
        "        num_layers,\n",
        "        heads,\n",
        "        forward_expansion,\n",
        "        dropout,\n",
        "        device,\n",
        "        max_length = 1024,\n",
        "    ):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.device = device\n",
        "        self.word_embedding = nn.Embedding(trg_vocab_size, embed_size)\n",
        "        self.position_embedding = nn.Embedding(max_length, embed_size)\n",
        "\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                DecoderBlock(embed_size, heads, forward_expansion, dropout, device),\n",
        "                DecoderBlock(embed_size, heads, forward_expansion, dropout, device),\n",
        "                DecoderBlock(embed_size, heads, forward_expansion, dropout, device),\n",
        "                DecoderBlock(embed_size, heads, forward_expansion, dropout, device),\n",
        "                DecoderBlock(embed_size, heads, forward_expansion, dropout, device)\n",
        "            ]\n",
        "        )\n",
        "        self.fc_out = nn.Linear(embed_size, trg_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_out, src_mask, row_mask,col_mask,conv_mask):\n",
        "        N, seq_length = x.shape\n",
        "        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
        "        x = self.dropout((self.word_embedding(x) + self.position_embedding(positions)))\n",
        "\n",
        "        x = self.layers[0](x, enc_out, enc_out, src_mask, row_mask)\n",
        "        x = self.layers[1](x, enc_out, enc_out, src_mask, col_mask)\n",
        "        x = self.layers[2](x, enc_out, enc_out, src_mask, row_mask)\n",
        "        x = self.layers[3](x, enc_out, enc_out, src_mask, row_mask)\n",
        "        x = self.layers[4](x, enc_out, enc_out, src_mask, conv_mask)\n",
        "        res = x[:, -1, :]  # [batch_size, num_class]\n",
        "        out = self.fc_out(x)\n",
        "\n",
        "        return [out, res]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PSn6pWBvaYXE"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        src_vocab_size,\n",
        "        trg_vocab_size,\n",
        "        src_pad_idx,\n",
        "        trg_pad_idx,\n",
        "        embed_size=512,\n",
        "        num_layers=6,\n",
        "        forward_expansion=4,\n",
        "        heads=8,\n",
        "        dropout=0,\n",
        "        device=\"gpu\",\n",
        "        max_length=1024,\n",
        "    ):\n",
        "\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(\n",
        "            src_vocab_size,\n",
        "            embed_size,\n",
        "            num_layers,\n",
        "            heads,\n",
        "            device,\n",
        "            forward_expansion,\n",
        "            dropout,\n",
        "            256,\n",
        "        )\n",
        "\n",
        "        self.decoder = Decoder(\n",
        "            trg_vocab_size,\n",
        "            embed_size,\n",
        "            num_layers,\n",
        "            heads,\n",
        "            forward_expansion,\n",
        "            dropout,\n",
        "            device,\n",
        "            1024,\n",
        "        )\n",
        "\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        # (N, 1, 1, src_len)\n",
        "        return src_mask.to(self.device)\n",
        "\n",
        "    def make_row_mask(self, trg):\n",
        "        N, trg_len = trg.shape\n",
        "\n",
        "        # trg_len = 32 * 32 = 1024\n",
        "        assert (\n",
        "            1024 == trg_len\n",
        "        ), \"The size of image vector is 1024\"\n",
        "\n",
        "        y_axis = torch.range(0, 1023).expand(1024,1024)\n",
        "        x_axis = torch.transpose(torch.range(0, 1023).expand(1024,1024), 0, 1)\n",
        "        trg_mask = ((y_axis<x_axis).long() + (y_axis+32>x_axis).long() -1).bool()\n",
        "\n",
        "        trg_mask = trg_mask.expand(N, 1, trg_len, trg_len)\n",
        "\n",
        "        return trg_mask.to(self.device)\n",
        "    \n",
        "    def make_col_mask(self, trg):\n",
        "        N, trg_len = trg.shape\n",
        "        # trg_len = 32 * 32 = 1024\n",
        "\n",
        "        assert (\n",
        "            1024 == trg_len\n",
        "        ), \"The size of image vector is 1024\"\n",
        "\n",
        "        trg_mask = torch.zeros(1024, 1024)\n",
        "        for i in range(32):\n",
        "          cur_dia = torch.ones((1, 1024-32*i))[0]\n",
        "          cur_mask = torch.diag(cur_dia,-32*i)\n",
        "          trg_mask = trg_mask + cur_mask\n",
        "\n",
        "        trg_mask = trg_mask.expand(N, 1, trg_len, trg_len)\n",
        "\n",
        "        return trg_mask.to(self.device)\n",
        "    \n",
        "    def make_conv_mask(self, trg):\n",
        "      # I am not sure how to deal with this(I searched online without finding the result),hence I will use row mask instead as they have similar performance\n",
        "        N, trg_len = trg.shape\n",
        "        # trg_len = 32 * 32 = 1024\n",
        "        assert (\n",
        "            1024 == trg_len\n",
        "        ), \"The size of image vector is 1024\"\n",
        "\n",
        "        y_axis = torch.range(0, 1023).expand(1024,1024)\n",
        "        x_axis = torch.transpose(torch.range(0, 1023).expand(1024,1024), 0, 1)\n",
        "        trg_mask = ((y_axis<x_axis).long() + (y_axis+32>x_axis).long() -1).bool()\n",
        "\n",
        "        trg_mask = trg_mask.expand(N, 1, trg_len, trg_len)\n",
        "\n",
        "        return trg_mask.to(self.device)\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        # src_mask = self.make_src_mask(src)\n",
        "        # trg_mask = self.make_trg_mask(trg)\n",
        "\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        row_mask = self.make_row_mask(trg)\n",
        "        col_mask = self.make_col_mask(trg)\n",
        "        conv_mask = self.make_conv_mask(trg)\n",
        "\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        out, res = self.decoder(trg, enc_src, src_mask, row_mask,col_mask,conv_mask)\n",
        "        return [out, res]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUT11_US_t6a"
      },
      "source": [
        "### dVAE model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "7F-yV2EXAco6"
      },
      "outputs": [],
      "source": [
        "# ! pip install DALL-E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "AyFm8diN_yKv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import io\n",
        "# import os, sys\n",
        "# import requests\n",
        "# import PIL\n",
        "\n",
        "# import torch\n",
        "# import torchvision.transforms as T\n",
        "# import torchvision.transforms.functional as TF\n",
        "\n",
        "# from dall_e          import map_pixels, unmap_pixels, load_model\n",
        "# from IPython.display import display, display_markdown\n",
        "\n",
        "# target_image_size = 256\n",
        "\n",
        "# def download_image(url):\n",
        "#     resp = requests.get(url)\n",
        "#     resp.raise_for_status()\n",
        "#     return PIL.Image.open(io.BytesIO(resp.content))\n",
        "\n",
        "# def preprocess(img):\n",
        "#     s = min(img.size)\n",
        "    \n",
        "#     if s < target_image_size:\n",
        "#         raise ValueError(f'min dim for image {s} < {target_image_size}')\n",
        "        \n",
        "#     r = target_image_size / s\n",
        "#     s = (round(r * img.size[1]), round(r * img.size[0]))\n",
        "#     img = TF.resize(img, s, interpolation=PIL.Image.LANCZOS)\n",
        "#     img = TF.center_crop(img, output_size=2 * [target_image_size])\n",
        "#     img = torch.unsqueeze(T.ToTensor()(img), 0)\n",
        "#     return map_pixels(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vFOPHOY1_3eR"
      },
      "outputs": [],
      "source": [
        "# # This can be changed to a GPU, e.g. 'cuda:0'.\n",
        "# dev = torch.device('cpu')\n",
        "\n",
        "# # For faster load times, download these files locally and use the local paths instead.\n",
        "# enc = load_model(\"https://cdn.openai.com/dall-e/encoder.pkl\", dev)\n",
        "# dec = load_model(\"https://cdn.openai.com/dall-e/decoder.pkl\", dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xCiBb8CTAA_l"
      },
      "outputs": [],
      "source": [
        "# x = preprocess(download_image('https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iKIWgaiJUtss/v2/1000x-1.jpg'))\n",
        "# display_markdown('Original image:')\n",
        "# display(T.ToPILImage(mode='RGB')(x[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-8dK3d9SAFGf"
      },
      "outputs": [],
      "source": [
        "# import torch.nn.functional as F\n",
        "\n",
        "# z_logits = enc(x)\n",
        "# z = torch.argmax(z_logits, axis=1)\n",
        "# print(z.shape)\n",
        "# z = F.one_hot(z, num_classes=enc.vocab_size).permute(0, 3, 1, 2).float()\n",
        "\n",
        "# x_stats = dec(z).float()\n",
        "# x_rec = unmap_pixels(torch.sigmoid(x_stats[:, :3]))\n",
        "# x_rec = T.ToPILImage(mode='RGB')(x_rec[0])\n",
        "\n",
        "# display_markdown('Reconstructed image:')\n",
        "# display(x_rec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "IqrVEbpcAxHe"
      },
      "outputs": [],
      "source": [
        "# z.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrCwfmLcv07-"
      },
      "source": [
        "### Generating part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "jo1wQeHfv4qh"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "def make_src_mask(src):\n",
        "  src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
        "  # (N, 1, 1, src_len)\n",
        "  return src_mask.to(device)\n",
        "\n",
        "def make_row_mask(trg):\n",
        "  N, trg_len = trg.shape\n",
        "  # trg_len = 32 * 32 = 1024\n",
        "  assert (\n",
        "      1024 == trg_len\n",
        "  ), \"The size of image vector is 1024\"\n",
        "\n",
        "  y_axis = torch.range(0, 1023).expand(1024,1024)\n",
        "  x_axis = torch.transpose(torch.range(0, 1023).expand(1024,1024), 0, 1)\n",
        "  trg_mask = ((y_axis<x_axis).long() + (y_axis+32>x_axis).long() -1).bool()\n",
        "\n",
        "  trg_mask = trg_mask.expand(N, 1, trg_len, trg_len)\n",
        "\n",
        "  return trg_mask.to(device)\n",
        "    \n",
        "def make_col_mask(trg):\n",
        "  N, trg_len = trg.shape\n",
        "  # trg_len = 32 * 32 = 1024\n",
        "\n",
        "  assert (\n",
        "      1024 == trg_len\n",
        "  ), \"The size of image vector is 1024\"\n",
        "\n",
        "  trg_mask = torch.zeros(1024, 1024)\n",
        "  for i in range(32):\n",
        "    cur_dia = torch.ones((1, 1024-32*i))[0]\n",
        "    cur_mask = torch.diag(cur_dia,-32*i)\n",
        "    trg_mask = trg_mask + cur_mask\n",
        "    trg_mask = trg_mask.expand(N, 1, trg_len, trg_len)\n",
        "\n",
        "    return trg_mask.to(device)\n",
        "    \n",
        "def make_conv_mask(trg):\n",
        "  # I am not sure how to deal with this(I searched online without finding the result),hence I will use row mask instead as they have similar performance\n",
        "  N, trg_len = trg.shape\n",
        "  # trg_len = 32 * 32 = 1024\n",
        "  assert (\n",
        "      1024 == trg_len\n",
        "  ), \"The size of image vector is 1024\"\n",
        "\n",
        "  y_axis = torch.range(0, 1023).expand(1024,1024)\n",
        "  x_axis = torch.transpose(torch.range(0, 1023).expand(1024,1024), 0, 1)\n",
        "  trg_mask = ((y_axis<x_axis).long() + (y_axis+32>x_axis).long() -1).bool()\n",
        "  trg_mask = trg_mask.expand(N, 1, trg_len, trg_len)\n",
        "\n",
        "  return trg_mask.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "SUvEeYFwlbFh"
      },
      "outputs": [],
      "source": [
        "def greedy_decode(model, src, src_mask, max_len, start_token, device):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        src: [bs, 1024]\n",
        "        start_token : [bs]\n",
        "        max_len : [1]\n",
        "    \"\"\"\n",
        "    memory = model.encoder(src, src_mask)  # forward(self, x, mask)\n",
        "    out_curr = torch.ones(src.shape[0], max_len).long().to(device)  # bs * 1024\n",
        "    out_curr[: , 0] = start_token.long() # bs * 1024\n",
        "\n",
        "    row_mask = make_row_mask(out_curr)\n",
        "    col_mask = make_col_mask(out_curr)\n",
        "    conv_mask = make_conv_mask(out_curr)\n",
        "\n",
        "    for i in range(max_len - 1):\n",
        "      out, res = model.decoder(out_curr, memory, src_mask, row_mask,col_mask,conv_mask)\n",
        "      prob = out[:, i] # [bs, d_x]\n",
        "      _, next_img = torch.max(prob, dim = 1) # [bs]\n",
        "      out_curr[:, i + 1] = next_img.long() \n",
        "    #print(res.shape)\n",
        "    return res "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "lj_RyScsp0sn"
      },
      "outputs": [],
      "source": [
        "# src_pad_idx = 0\n",
        "# trg_pad_idx = 0\n",
        "# src_vocab_size = 49\n",
        "# trg_vocab_size = 8192\n",
        "# model = Transformer(src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, device=device).to(device)\n",
        "\n",
        "# model.load_state_dict(checkpt[\"model\"])\n",
        "# model.eval()\n",
        "# #hidden_out = []\n",
        "# i = 0\n",
        "# for batch_idx, (x, y, z) in enumerate(train_dataloader):\n",
        "#   x = x.to(device) \n",
        "#   y = y.to(device) \n",
        "#   z = z.to(device) #[batch_size]\n",
        "#   src_mask = make_src_mask(x)\n",
        "    \n",
        "#   hidden_out = greedy_decode(model, x, src_mask, max_len=1024, start_token=z, device=device)\n",
        "#   print(hidden_out)\n",
        "#   if i == 0:\n",
        "#     df = pd.DataFrame(hidden_out.cpu().detach().numpy(), columns = range(512))\n",
        "#   if i > 2:\n",
        "#     break\n",
        "#   else:\n",
        "#     df = pd.concat([df, pd.DataFrame(hidden_out.cpu().detach().numpy(), columns = range(512))])\n",
        "#   i = i + 1\n",
        "#   hidden_out = 0\n",
        "#   print(i)\n",
        "# #print(hidden_out)\n",
        "# #print(hidden_out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df"
      ],
      "metadata": {
        "id": "9MpkfVELKl6X"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.to_csv('training_data_mlp.csv', index=False)"
      ],
      "metadata": {
        "id": "B8pomCGBgRkQ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_pad_idx = 0\n",
        "trg_pad_idx = 0\n",
        "src_vocab_size = 49\n",
        "trg_vocab_size = 8192\n",
        "model = Transformer(src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, device=device).to(device)\n",
        "\n",
        "model.load_state_dict(checkpt[\"model\"])\n",
        "model.eval()\n",
        "i = 0\n",
        "for batch_idx, (x, y, z) in enumerate(test_dataloader):\n",
        "  x = x.to(device) \n",
        "  y = y.to(device) \n",
        "  z = z.to(device) #[batch_size]\n",
        "  src_mask = make_src_mask(x)\n",
        "    \n",
        "  hidden_out_test = greedy_decode(model, x, src_mask, \n",
        "                        max_len=1024, start_token=z, device=device)\n",
        "  if i == 0:\n",
        "    df = pd.DataFrame(hidden_out_test.cpu().detach().numpy(), columns = range(512))\n",
        "  else:\n",
        "    df = pd.concat([df, pd.DataFrame(hidden_out_test.cpu().detach().numpy(), columns = range(512))])\n",
        "  i = i + 1\n",
        "  hidden_out_test = 0\n",
        "  print(i)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQeUqJX3Figw",
        "outputId": "7ee218ee-f26d-4bce-dc89-2dbad061a65d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "BeU-B_0xMXYB",
        "outputId": "38e57bff-00a3-4502-82d0-93912651bdbc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5253c9fe-0881-42d1-9814-7aeb1f8ab293\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>472</th>\n",
              "      <th>473</th>\n",
              "      <th>474</th>\n",
              "      <th>475</th>\n",
              "      <th>476</th>\n",
              "      <th>477</th>\n",
              "      <th>478</th>\n",
              "      <th>479</th>\n",
              "      <th>480</th>\n",
              "      <th>481</th>\n",
              "      <th>482</th>\n",
              "      <th>483</th>\n",
              "      <th>484</th>\n",
              "      <th>485</th>\n",
              "      <th>486</th>\n",
              "      <th>487</th>\n",
              "      <th>488</th>\n",
              "      <th>489</th>\n",
              "      <th>490</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "      <th>500</th>\n",
              "      <th>501</th>\n",
              "      <th>502</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.863567</td>\n",
              "      <td>-0.570675</td>\n",
              "      <td>2.186903</td>\n",
              "      <td>0.342062</td>\n",
              "      <td>-0.107246</td>\n",
              "      <td>0.026681</td>\n",
              "      <td>0.329385</td>\n",
              "      <td>0.449422</td>\n",
              "      <td>-0.157975</td>\n",
              "      <td>-0.506781</td>\n",
              "      <td>1.508040</td>\n",
              "      <td>1.084914</td>\n",
              "      <td>0.211265</td>\n",
              "      <td>-0.355420</td>\n",
              "      <td>0.714799</td>\n",
              "      <td>-0.461057</td>\n",
              "      <td>-0.444154</td>\n",
              "      <td>2.013007</td>\n",
              "      <td>-1.132530</td>\n",
              "      <td>0.230622</td>\n",
              "      <td>0.229829</td>\n",
              "      <td>-0.165674</td>\n",
              "      <td>-0.921479</td>\n",
              "      <td>-0.175453</td>\n",
              "      <td>0.773221</td>\n",
              "      <td>0.279488</td>\n",
              "      <td>-0.031898</td>\n",
              "      <td>0.755713</td>\n",
              "      <td>0.076252</td>\n",
              "      <td>0.617354</td>\n",
              "      <td>0.733818</td>\n",
              "      <td>-2.205909</td>\n",
              "      <td>-0.604884</td>\n",
              "      <td>0.488294</td>\n",
              "      <td>-0.365742</td>\n",
              "      <td>-1.374590</td>\n",
              "      <td>-0.226334</td>\n",
              "      <td>-0.768291</td>\n",
              "      <td>0.393575</td>\n",
              "      <td>-1.290212</td>\n",
              "      <td>...</td>\n",
              "      <td>0.297538</td>\n",
              "      <td>-0.303403</td>\n",
              "      <td>0.092897</td>\n",
              "      <td>1.617078</td>\n",
              "      <td>0.779390</td>\n",
              "      <td>1.589893</td>\n",
              "      <td>0.802914</td>\n",
              "      <td>-0.220412</td>\n",
              "      <td>-0.031898</td>\n",
              "      <td>1.562983</td>\n",
              "      <td>-1.005122</td>\n",
              "      <td>-0.793130</td>\n",
              "      <td>-0.255766</td>\n",
              "      <td>1.318296</td>\n",
              "      <td>3.131931</td>\n",
              "      <td>0.422514</td>\n",
              "      <td>-1.055240</td>\n",
              "      <td>-0.809156</td>\n",
              "      <td>0.265202</td>\n",
              "      <td>0.549371</td>\n",
              "      <td>-0.638051</td>\n",
              "      <td>0.010624</td>\n",
              "      <td>1.043703</td>\n",
              "      <td>-1.142635</td>\n",
              "      <td>-0.435704</td>\n",
              "      <td>-0.647465</td>\n",
              "      <td>1.125153</td>\n",
              "      <td>-0.381220</td>\n",
              "      <td>-0.808859</td>\n",
              "      <td>-1.078182</td>\n",
              "      <td>-0.268686</td>\n",
              "      <td>-0.045226</td>\n",
              "      <td>2.371692</td>\n",
              "      <td>-0.903736</td>\n",
              "      <td>-0.096707</td>\n",
              "      <td>0.261661</td>\n",
              "      <td>-0.851519</td>\n",
              "      <td>-0.376124</td>\n",
              "      <td>0.448598</td>\n",
              "      <td>1.668019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.335494</td>\n",
              "      <td>0.292490</td>\n",
              "      <td>-0.508044</td>\n",
              "      <td>-1.153627</td>\n",
              "      <td>0.540390</td>\n",
              "      <td>0.206045</td>\n",
              "      <td>0.010990</td>\n",
              "      <td>1.304706</td>\n",
              "      <td>-0.538541</td>\n",
              "      <td>-0.326502</td>\n",
              "      <td>0.302313</td>\n",
              "      <td>-0.651378</td>\n",
              "      <td>-0.202800</td>\n",
              "      <td>0.629772</td>\n",
              "      <td>0.371249</td>\n",
              "      <td>-0.324261</td>\n",
              "      <td>-0.694094</td>\n",
              "      <td>1.677536</td>\n",
              "      <td>-0.547544</td>\n",
              "      <td>0.898258</td>\n",
              "      <td>1.244230</td>\n",
              "      <td>0.617386</td>\n",
              "      <td>-1.555147</td>\n",
              "      <td>-0.425234</td>\n",
              "      <td>-1.793179</td>\n",
              "      <td>1.522953</td>\n",
              "      <td>-0.544739</td>\n",
              "      <td>-0.809806</td>\n",
              "      <td>-0.276967</td>\n",
              "      <td>-0.151111</td>\n",
              "      <td>1.508566</td>\n",
              "      <td>-0.490677</td>\n",
              "      <td>1.034442</td>\n",
              "      <td>1.041839</td>\n",
              "      <td>0.125563</td>\n",
              "      <td>-0.308793</td>\n",
              "      <td>1.344633</td>\n",
              "      <td>0.932389</td>\n",
              "      <td>0.024786</td>\n",
              "      <td>-1.020249</td>\n",
              "      <td>...</td>\n",
              "      <td>0.560303</td>\n",
              "      <td>-0.123026</td>\n",
              "      <td>0.046601</td>\n",
              "      <td>0.086926</td>\n",
              "      <td>0.313804</td>\n",
              "      <td>1.956427</td>\n",
              "      <td>-0.487532</td>\n",
              "      <td>0.445130</td>\n",
              "      <td>0.125909</td>\n",
              "      <td>0.819535</td>\n",
              "      <td>1.801975</td>\n",
              "      <td>-0.118825</td>\n",
              "      <td>0.874371</td>\n",
              "      <td>0.240556</td>\n",
              "      <td>1.920498</td>\n",
              "      <td>0.419769</td>\n",
              "      <td>-2.114433</td>\n",
              "      <td>-2.155768</td>\n",
              "      <td>0.125470</td>\n",
              "      <td>0.187012</td>\n",
              "      <td>-1.206990</td>\n",
              "      <td>0.362536</td>\n",
              "      <td>0.322836</td>\n",
              "      <td>-0.747835</td>\n",
              "      <td>0.894047</td>\n",
              "      <td>0.555354</td>\n",
              "      <td>0.223310</td>\n",
              "      <td>-0.460713</td>\n",
              "      <td>-0.382474</td>\n",
              "      <td>0.101025</td>\n",
              "      <td>-0.493817</td>\n",
              "      <td>0.112523</td>\n",
              "      <td>2.793901</td>\n",
              "      <td>-1.576281</td>\n",
              "      <td>-0.597879</td>\n",
              "      <td>-0.123535</td>\n",
              "      <td>-1.407694</td>\n",
              "      <td>0.727233</td>\n",
              "      <td>1.154358</td>\n",
              "      <td>2.425046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.869617</td>\n",
              "      <td>0.700056</td>\n",
              "      <td>2.544178</td>\n",
              "      <td>0.335212</td>\n",
              "      <td>-0.729777</td>\n",
              "      <td>0.127041</td>\n",
              "      <td>1.372651</td>\n",
              "      <td>0.003738</td>\n",
              "      <td>-0.035011</td>\n",
              "      <td>-1.872553</td>\n",
              "      <td>1.099311</td>\n",
              "      <td>0.607663</td>\n",
              "      <td>1.070125</td>\n",
              "      <td>-0.059764</td>\n",
              "      <td>1.031530</td>\n",
              "      <td>1.875414</td>\n",
              "      <td>1.254386</td>\n",
              "      <td>0.853875</td>\n",
              "      <td>-0.940863</td>\n",
              "      <td>-1.121300</td>\n",
              "      <td>0.213144</td>\n",
              "      <td>-1.401598</td>\n",
              "      <td>-0.830637</td>\n",
              "      <td>-0.025231</td>\n",
              "      <td>1.458889</td>\n",
              "      <td>-2.836923</td>\n",
              "      <td>-0.802549</td>\n",
              "      <td>-0.451039</td>\n",
              "      <td>0.043068</td>\n",
              "      <td>0.727391</td>\n",
              "      <td>-1.346132</td>\n",
              "      <td>-0.900911</td>\n",
              "      <td>-0.206616</td>\n",
              "      <td>-0.895753</td>\n",
              "      <td>1.074682</td>\n",
              "      <td>0.239226</td>\n",
              "      <td>-2.445189</td>\n",
              "      <td>-1.311834</td>\n",
              "      <td>0.493376</td>\n",
              "      <td>-1.026084</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.472762</td>\n",
              "      <td>0.214473</td>\n",
              "      <td>-0.528650</td>\n",
              "      <td>2.397090</td>\n",
              "      <td>0.982042</td>\n",
              "      <td>-0.260087</td>\n",
              "      <td>2.482381</td>\n",
              "      <td>-0.535913</td>\n",
              "      <td>0.106498</td>\n",
              "      <td>1.189679</td>\n",
              "      <td>-0.565402</td>\n",
              "      <td>0.006602</td>\n",
              "      <td>-1.950040</td>\n",
              "      <td>1.668866</td>\n",
              "      <td>2.401486</td>\n",
              "      <td>0.296126</td>\n",
              "      <td>0.689231</td>\n",
              "      <td>0.094611</td>\n",
              "      <td>0.587073</td>\n",
              "      <td>0.298768</td>\n",
              "      <td>-0.182701</td>\n",
              "      <td>0.813359</td>\n",
              "      <td>1.474480</td>\n",
              "      <td>0.927866</td>\n",
              "      <td>-0.360115</td>\n",
              "      <td>0.994289</td>\n",
              "      <td>-0.047324</td>\n",
              "      <td>0.160352</td>\n",
              "      <td>-0.043486</td>\n",
              "      <td>-1.417518</td>\n",
              "      <td>-0.851041</td>\n",
              "      <td>0.571906</td>\n",
              "      <td>0.744820</td>\n",
              "      <td>-0.290792</td>\n",
              "      <td>0.470355</td>\n",
              "      <td>2.459215</td>\n",
              "      <td>1.162291</td>\n",
              "      <td>0.174274</td>\n",
              "      <td>0.524155</td>\n",
              "      <td>0.025221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.143558</td>\n",
              "      <td>0.006077</td>\n",
              "      <td>-0.493171</td>\n",
              "      <td>-0.519366</td>\n",
              "      <td>0.064887</td>\n",
              "      <td>-1.035058</td>\n",
              "      <td>-0.447165</td>\n",
              "      <td>2.139800</td>\n",
              "      <td>-0.654380</td>\n",
              "      <td>1.408648</td>\n",
              "      <td>-0.295009</td>\n",
              "      <td>-1.574678</td>\n",
              "      <td>-0.112276</td>\n",
              "      <td>0.692985</td>\n",
              "      <td>-0.731981</td>\n",
              "      <td>2.130375</td>\n",
              "      <td>0.183835</td>\n",
              "      <td>1.539065</td>\n",
              "      <td>-1.162314</td>\n",
              "      <td>-0.045224</td>\n",
              "      <td>0.751372</td>\n",
              "      <td>-0.336167</td>\n",
              "      <td>-0.307350</td>\n",
              "      <td>0.677160</td>\n",
              "      <td>-0.459027</td>\n",
              "      <td>1.729837</td>\n",
              "      <td>0.670097</td>\n",
              "      <td>2.193301</td>\n",
              "      <td>-0.676917</td>\n",
              "      <td>-0.216017</td>\n",
              "      <td>1.584823</td>\n",
              "      <td>0.219403</td>\n",
              "      <td>1.432169</td>\n",
              "      <td>0.287089</td>\n",
              "      <td>0.117677</td>\n",
              "      <td>-2.135802</td>\n",
              "      <td>1.692822</td>\n",
              "      <td>1.476736</td>\n",
              "      <td>-0.051562</td>\n",
              "      <td>0.907624</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.549393</td>\n",
              "      <td>0.791569</td>\n",
              "      <td>0.363926</td>\n",
              "      <td>-1.198233</td>\n",
              "      <td>-0.629785</td>\n",
              "      <td>-0.029873</td>\n",
              "      <td>0.277115</td>\n",
              "      <td>0.774908</td>\n",
              "      <td>1.128809</td>\n",
              "      <td>-0.413325</td>\n",
              "      <td>1.020223</td>\n",
              "      <td>-0.655029</td>\n",
              "      <td>1.203703</td>\n",
              "      <td>0.729719</td>\n",
              "      <td>1.683257</td>\n",
              "      <td>0.050777</td>\n",
              "      <td>-2.632540</td>\n",
              "      <td>-1.959673</td>\n",
              "      <td>0.375993</td>\n",
              "      <td>1.167294</td>\n",
              "      <td>-0.688254</td>\n",
              "      <td>-0.123560</td>\n",
              "      <td>1.446461</td>\n",
              "      <td>0.459580</td>\n",
              "      <td>2.010222</td>\n",
              "      <td>1.371670</td>\n",
              "      <td>-1.813241</td>\n",
              "      <td>-0.265259</td>\n",
              "      <td>-0.451632</td>\n",
              "      <td>-0.485660</td>\n",
              "      <td>-0.531378</td>\n",
              "      <td>0.604779</td>\n",
              "      <td>2.078222</td>\n",
              "      <td>-0.015009</td>\n",
              "      <td>-0.979966</td>\n",
              "      <td>0.980506</td>\n",
              "      <td>0.472184</td>\n",
              "      <td>0.562645</td>\n",
              "      <td>0.800046</td>\n",
              "      <td>1.888708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.222054</td>\n",
              "      <td>0.008657</td>\n",
              "      <td>0.506482</td>\n",
              "      <td>-1.876514</td>\n",
              "      <td>-0.050197</td>\n",
              "      <td>-1.145855</td>\n",
              "      <td>-0.636825</td>\n",
              "      <td>0.563957</td>\n",
              "      <td>-0.243259</td>\n",
              "      <td>0.880066</td>\n",
              "      <td>-0.557536</td>\n",
              "      <td>-0.555836</td>\n",
              "      <td>0.019160</td>\n",
              "      <td>1.014540</td>\n",
              "      <td>1.054555</td>\n",
              "      <td>-1.270604</td>\n",
              "      <td>-1.107479</td>\n",
              "      <td>-1.718342</td>\n",
              "      <td>-1.980413</td>\n",
              "      <td>1.656512</td>\n",
              "      <td>-0.064170</td>\n",
              "      <td>0.727024</td>\n",
              "      <td>-2.266407</td>\n",
              "      <td>-0.113691</td>\n",
              "      <td>-1.051660</td>\n",
              "      <td>1.033901</td>\n",
              "      <td>-0.374226</td>\n",
              "      <td>-0.470933</td>\n",
              "      <td>-1.076191</td>\n",
              "      <td>-0.067301</td>\n",
              "      <td>1.947644</td>\n",
              "      <td>-0.905874</td>\n",
              "      <td>-1.796928</td>\n",
              "      <td>0.027091</td>\n",
              "      <td>-1.989592</td>\n",
              "      <td>1.939876</td>\n",
              "      <td>0.944803</td>\n",
              "      <td>-0.178005</td>\n",
              "      <td>-0.065498</td>\n",
              "      <td>2.330902</td>\n",
              "      <td>...</td>\n",
              "      <td>0.195956</td>\n",
              "      <td>0.445528</td>\n",
              "      <td>0.020233</td>\n",
              "      <td>1.734710</td>\n",
              "      <td>-0.323329</td>\n",
              "      <td>1.589604</td>\n",
              "      <td>-2.185665</td>\n",
              "      <td>0.826422</td>\n",
              "      <td>-0.743552</td>\n",
              "      <td>-1.798128</td>\n",
              "      <td>-0.043457</td>\n",
              "      <td>-1.250349</td>\n",
              "      <td>1.300195</td>\n",
              "      <td>-1.079261</td>\n",
              "      <td>0.769380</td>\n",
              "      <td>0.065627</td>\n",
              "      <td>-1.560810</td>\n",
              "      <td>-0.967591</td>\n",
              "      <td>-0.256781</td>\n",
              "      <td>0.001851</td>\n",
              "      <td>1.117204</td>\n",
              "      <td>-0.638498</td>\n",
              "      <td>-0.636039</td>\n",
              "      <td>-0.027110</td>\n",
              "      <td>0.430437</td>\n",
              "      <td>-0.890558</td>\n",
              "      <td>-0.066978</td>\n",
              "      <td>0.123404</td>\n",
              "      <td>-0.044269</td>\n",
              "      <td>0.721552</td>\n",
              "      <td>0.246876</td>\n",
              "      <td>-1.418113</td>\n",
              "      <td>-0.073837</td>\n",
              "      <td>-1.086767</td>\n",
              "      <td>-0.121392</td>\n",
              "      <td>0.555426</td>\n",
              "      <td>-2.241349</td>\n",
              "      <td>-1.591113</td>\n",
              "      <td>0.087331</td>\n",
              "      <td>-1.365646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.856003</td>\n",
              "      <td>-0.090863</td>\n",
              "      <td>2.167351</td>\n",
              "      <td>-0.237390</td>\n",
              "      <td>0.736640</td>\n",
              "      <td>0.999222</td>\n",
              "      <td>0.503169</td>\n",
              "      <td>-0.112196</td>\n",
              "      <td>-0.874257</td>\n",
              "      <td>-1.917956</td>\n",
              "      <td>1.308753</td>\n",
              "      <td>-1.084285</td>\n",
              "      <td>0.055040</td>\n",
              "      <td>0.402122</td>\n",
              "      <td>-0.856256</td>\n",
              "      <td>2.328046</td>\n",
              "      <td>0.807180</td>\n",
              "      <td>1.028255</td>\n",
              "      <td>-0.558853</td>\n",
              "      <td>-0.716101</td>\n",
              "      <td>0.930124</td>\n",
              "      <td>-0.431853</td>\n",
              "      <td>-0.606696</td>\n",
              "      <td>0.466209</td>\n",
              "      <td>1.204909</td>\n",
              "      <td>0.492413</td>\n",
              "      <td>0.012170</td>\n",
              "      <td>1.117362</td>\n",
              "      <td>0.135333</td>\n",
              "      <td>0.294777</td>\n",
              "      <td>-0.142948</td>\n",
              "      <td>0.016139</td>\n",
              "      <td>0.756026</td>\n",
              "      <td>0.670227</td>\n",
              "      <td>1.527007</td>\n",
              "      <td>-1.831275</td>\n",
              "      <td>-0.306833</td>\n",
              "      <td>0.076247</td>\n",
              "      <td>-0.443237</td>\n",
              "      <td>-0.980405</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.556923</td>\n",
              "      <td>-0.081590</td>\n",
              "      <td>0.596097</td>\n",
              "      <td>-2.025904</td>\n",
              "      <td>0.038874</td>\n",
              "      <td>-0.213377</td>\n",
              "      <td>1.405352</td>\n",
              "      <td>1.242039</td>\n",
              "      <td>0.382582</td>\n",
              "      <td>2.176861</td>\n",
              "      <td>0.126949</td>\n",
              "      <td>-2.897427</td>\n",
              "      <td>-1.320428</td>\n",
              "      <td>1.949598</td>\n",
              "      <td>1.635879</td>\n",
              "      <td>-0.103910</td>\n",
              "      <td>0.039310</td>\n",
              "      <td>0.653031</td>\n",
              "      <td>1.227988</td>\n",
              "      <td>1.310022</td>\n",
              "      <td>-1.376630</td>\n",
              "      <td>0.101011</td>\n",
              "      <td>1.950914</td>\n",
              "      <td>-0.154916</td>\n",
              "      <td>1.298893</td>\n",
              "      <td>1.399602</td>\n",
              "      <td>0.076762</td>\n",
              "      <td>-0.118274</td>\n",
              "      <td>-0.564663</td>\n",
              "      <td>-1.116065</td>\n",
              "      <td>-0.813594</td>\n",
              "      <td>0.914215</td>\n",
              "      <td>1.065916</td>\n",
              "      <td>0.165018</td>\n",
              "      <td>-0.325913</td>\n",
              "      <td>0.664688</td>\n",
              "      <td>-0.482666</td>\n",
              "      <td>-0.022574</td>\n",
              "      <td>-0.419768</td>\n",
              "      <td>2.290327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2.263805</td>\n",
              "      <td>0.194879</td>\n",
              "      <td>2.773061</td>\n",
              "      <td>0.880687</td>\n",
              "      <td>0.240621</td>\n",
              "      <td>-0.769074</td>\n",
              "      <td>0.055948</td>\n",
              "      <td>1.007381</td>\n",
              "      <td>0.046693</td>\n",
              "      <td>-0.049417</td>\n",
              "      <td>0.592672</td>\n",
              "      <td>-0.007445</td>\n",
              "      <td>0.787140</td>\n",
              "      <td>0.642700</td>\n",
              "      <td>0.526424</td>\n",
              "      <td>1.663723</td>\n",
              "      <td>-0.004243</td>\n",
              "      <td>1.035262</td>\n",
              "      <td>-0.956585</td>\n",
              "      <td>0.413167</td>\n",
              "      <td>1.336500</td>\n",
              "      <td>0.246324</td>\n",
              "      <td>-2.771273</td>\n",
              "      <td>0.328122</td>\n",
              "      <td>-1.214333</td>\n",
              "      <td>-0.622734</td>\n",
              "      <td>-0.650096</td>\n",
              "      <td>-1.530857</td>\n",
              "      <td>0.494506</td>\n",
              "      <td>1.055699</td>\n",
              "      <td>-0.154851</td>\n",
              "      <td>-0.227239</td>\n",
              "      <td>1.259040</td>\n",
              "      <td>1.509612</td>\n",
              "      <td>-0.521477</td>\n",
              "      <td>0.015898</td>\n",
              "      <td>1.206808</td>\n",
              "      <td>1.034360</td>\n",
              "      <td>0.525979</td>\n",
              "      <td>-1.144008</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.911315</td>\n",
              "      <td>-0.056617</td>\n",
              "      <td>-0.159695</td>\n",
              "      <td>1.496232</td>\n",
              "      <td>0.778983</td>\n",
              "      <td>1.434108</td>\n",
              "      <td>-0.849369</td>\n",
              "      <td>-0.536231</td>\n",
              "      <td>-0.198232</td>\n",
              "      <td>1.373321</td>\n",
              "      <td>-0.201818</td>\n",
              "      <td>-0.529346</td>\n",
              "      <td>-0.486978</td>\n",
              "      <td>1.162249</td>\n",
              "      <td>1.860968</td>\n",
              "      <td>-0.501750</td>\n",
              "      <td>-1.179303</td>\n",
              "      <td>-1.348243</td>\n",
              "      <td>0.535148</td>\n",
              "      <td>-0.185919</td>\n",
              "      <td>-0.789481</td>\n",
              "      <td>1.069027</td>\n",
              "      <td>0.223284</td>\n",
              "      <td>0.531847</td>\n",
              "      <td>0.668204</td>\n",
              "      <td>0.012631</td>\n",
              "      <td>0.198606</td>\n",
              "      <td>0.131072</td>\n",
              "      <td>0.463368</td>\n",
              "      <td>-1.025219</td>\n",
              "      <td>-1.164728</td>\n",
              "      <td>-0.306580</td>\n",
              "      <td>2.419559</td>\n",
              "      <td>-2.146252</td>\n",
              "      <td>-1.022943</td>\n",
              "      <td>1.102539</td>\n",
              "      <td>-1.217293</td>\n",
              "      <td>2.197751</td>\n",
              "      <td>1.442113</td>\n",
              "      <td>0.696673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.510298</td>\n",
              "      <td>1.078710</td>\n",
              "      <td>2.728060</td>\n",
              "      <td>-1.310970</td>\n",
              "      <td>-0.559863</td>\n",
              "      <td>0.599714</td>\n",
              "      <td>0.376202</td>\n",
              "      <td>1.198620</td>\n",
              "      <td>0.676041</td>\n",
              "      <td>0.146096</td>\n",
              "      <td>0.252785</td>\n",
              "      <td>0.252838</td>\n",
              "      <td>-0.128636</td>\n",
              "      <td>1.241891</td>\n",
              "      <td>-0.824413</td>\n",
              "      <td>-0.421368</td>\n",
              "      <td>-2.416066</td>\n",
              "      <td>-0.987371</td>\n",
              "      <td>-1.712228</td>\n",
              "      <td>-0.440545</td>\n",
              "      <td>0.127843</td>\n",
              "      <td>1.097946</td>\n",
              "      <td>-0.735496</td>\n",
              "      <td>0.271355</td>\n",
              "      <td>2.562643</td>\n",
              "      <td>-2.381709</td>\n",
              "      <td>-1.283091</td>\n",
              "      <td>0.004149</td>\n",
              "      <td>-0.259016</td>\n",
              "      <td>1.068403</td>\n",
              "      <td>0.999696</td>\n",
              "      <td>0.200155</td>\n",
              "      <td>-1.009113</td>\n",
              "      <td>-0.814349</td>\n",
              "      <td>-0.551130</td>\n",
              "      <td>0.308155</td>\n",
              "      <td>1.496403</td>\n",
              "      <td>-0.869608</td>\n",
              "      <td>-0.089490</td>\n",
              "      <td>1.218838</td>\n",
              "      <td>...</td>\n",
              "      <td>0.459245</td>\n",
              "      <td>-0.015475</td>\n",
              "      <td>-0.034373</td>\n",
              "      <td>0.086070</td>\n",
              "      <td>-1.289134</td>\n",
              "      <td>1.432149</td>\n",
              "      <td>-0.158887</td>\n",
              "      <td>-0.158554</td>\n",
              "      <td>1.248507</td>\n",
              "      <td>0.760620</td>\n",
              "      <td>-1.640828</td>\n",
              "      <td>-1.755564</td>\n",
              "      <td>-1.912212</td>\n",
              "      <td>1.094712</td>\n",
              "      <td>0.244196</td>\n",
              "      <td>-0.314758</td>\n",
              "      <td>1.320556</td>\n",
              "      <td>1.226345</td>\n",
              "      <td>-0.396340</td>\n",
              "      <td>0.267958</td>\n",
              "      <td>-0.233522</td>\n",
              "      <td>-0.163587</td>\n",
              "      <td>1.551350</td>\n",
              "      <td>-0.608256</td>\n",
              "      <td>0.568023</td>\n",
              "      <td>1.620605</td>\n",
              "      <td>-0.236821</td>\n",
              "      <td>0.326515</td>\n",
              "      <td>-0.165388</td>\n",
              "      <td>-0.175040</td>\n",
              "      <td>0.019051</td>\n",
              "      <td>0.123634</td>\n",
              "      <td>1.028484</td>\n",
              "      <td>-0.186148</td>\n",
              "      <td>0.223780</td>\n",
              "      <td>1.379269</td>\n",
              "      <td>-1.024280</td>\n",
              "      <td>0.374264</td>\n",
              "      <td>0.934539</td>\n",
              "      <td>-0.042964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.137370</td>\n",
              "      <td>0.082786</td>\n",
              "      <td>0.450325</td>\n",
              "      <td>-2.067375</td>\n",
              "      <td>-0.096434</td>\n",
              "      <td>-1.111743</td>\n",
              "      <td>-0.702600</td>\n",
              "      <td>0.546813</td>\n",
              "      <td>-0.289284</td>\n",
              "      <td>0.836196</td>\n",
              "      <td>-0.500809</td>\n",
              "      <td>-0.548388</td>\n",
              "      <td>-0.012069</td>\n",
              "      <td>1.128207</td>\n",
              "      <td>0.884369</td>\n",
              "      <td>-1.220346</td>\n",
              "      <td>-1.050596</td>\n",
              "      <td>-1.864343</td>\n",
              "      <td>-1.864187</td>\n",
              "      <td>1.727725</td>\n",
              "      <td>-0.104424</td>\n",
              "      <td>0.802572</td>\n",
              "      <td>-2.265931</td>\n",
              "      <td>-0.147590</td>\n",
              "      <td>-1.034572</td>\n",
              "      <td>1.199182</td>\n",
              "      <td>-0.356549</td>\n",
              "      <td>-0.514955</td>\n",
              "      <td>-1.166484</td>\n",
              "      <td>-0.182703</td>\n",
              "      <td>1.969887</td>\n",
              "      <td>-0.790487</td>\n",
              "      <td>-1.659699</td>\n",
              "      <td>-0.023600</td>\n",
              "      <td>-1.934463</td>\n",
              "      <td>1.922052</td>\n",
              "      <td>0.956756</td>\n",
              "      <td>-0.180240</td>\n",
              "      <td>-0.133466</td>\n",
              "      <td>2.329875</td>\n",
              "      <td>...</td>\n",
              "      <td>0.208668</td>\n",
              "      <td>0.437082</td>\n",
              "      <td>-0.016576</td>\n",
              "      <td>1.481172</td>\n",
              "      <td>-0.335991</td>\n",
              "      <td>1.641092</td>\n",
              "      <td>-2.285945</td>\n",
              "      <td>0.832362</td>\n",
              "      <td>-0.727774</td>\n",
              "      <td>-1.673419</td>\n",
              "      <td>0.002796</td>\n",
              "      <td>-1.386986</td>\n",
              "      <td>1.374839</td>\n",
              "      <td>-1.067959</td>\n",
              "      <td>0.707580</td>\n",
              "      <td>0.166474</td>\n",
              "      <td>-1.574714</td>\n",
              "      <td>-1.036814</td>\n",
              "      <td>-0.256968</td>\n",
              "      <td>0.063276</td>\n",
              "      <td>1.092494</td>\n",
              "      <td>-0.598936</td>\n",
              "      <td>-0.693626</td>\n",
              "      <td>-0.049732</td>\n",
              "      <td>0.467340</td>\n",
              "      <td>-0.746196</td>\n",
              "      <td>-0.035769</td>\n",
              "      <td>0.082431</td>\n",
              "      <td>-0.003551</td>\n",
              "      <td>0.874802</td>\n",
              "      <td>0.342693</td>\n",
              "      <td>-1.379282</td>\n",
              "      <td>-0.006814</td>\n",
              "      <td>-0.851673</td>\n",
              "      <td>-0.150799</td>\n",
              "      <td>0.573579</td>\n",
              "      <td>-2.228807</td>\n",
              "      <td>-1.549646</td>\n",
              "      <td>0.054569</td>\n",
              "      <td>-1.326485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.222346</td>\n",
              "      <td>0.008665</td>\n",
              "      <td>0.506922</td>\n",
              "      <td>-1.876602</td>\n",
              "      <td>-0.050091</td>\n",
              "      <td>-1.145725</td>\n",
              "      <td>-0.637202</td>\n",
              "      <td>0.563989</td>\n",
              "      <td>-0.243228</td>\n",
              "      <td>0.879841</td>\n",
              "      <td>-0.557306</td>\n",
              "      <td>-0.556070</td>\n",
              "      <td>0.019116</td>\n",
              "      <td>1.014653</td>\n",
              "      <td>1.054181</td>\n",
              "      <td>-1.270671</td>\n",
              "      <td>-1.107268</td>\n",
              "      <td>-1.718369</td>\n",
              "      <td>-1.980019</td>\n",
              "      <td>1.656672</td>\n",
              "      <td>-0.064196</td>\n",
              "      <td>0.727474</td>\n",
              "      <td>-2.266695</td>\n",
              "      <td>-0.113843</td>\n",
              "      <td>-1.051523</td>\n",
              "      <td>1.033864</td>\n",
              "      <td>-0.374532</td>\n",
              "      <td>-0.470950</td>\n",
              "      <td>-1.076267</td>\n",
              "      <td>-0.067309</td>\n",
              "      <td>1.947197</td>\n",
              "      <td>-0.905976</td>\n",
              "      <td>-1.797567</td>\n",
              "      <td>0.027126</td>\n",
              "      <td>-1.989291</td>\n",
              "      <td>1.939623</td>\n",
              "      <td>0.944575</td>\n",
              "      <td>-0.178421</td>\n",
              "      <td>-0.065327</td>\n",
              "      <td>2.330897</td>\n",
              "      <td>...</td>\n",
              "      <td>0.195851</td>\n",
              "      <td>0.445685</td>\n",
              "      <td>0.020225</td>\n",
              "      <td>1.734370</td>\n",
              "      <td>-0.323294</td>\n",
              "      <td>1.589656</td>\n",
              "      <td>-2.185362</td>\n",
              "      <td>0.826489</td>\n",
              "      <td>-0.743483</td>\n",
              "      <td>-1.798429</td>\n",
              "      <td>-0.043645</td>\n",
              "      <td>-1.250524</td>\n",
              "      <td>1.299955</td>\n",
              "      <td>-1.079061</td>\n",
              "      <td>0.769234</td>\n",
              "      <td>0.065664</td>\n",
              "      <td>-1.560555</td>\n",
              "      <td>-0.967435</td>\n",
              "      <td>-0.257005</td>\n",
              "      <td>0.001682</td>\n",
              "      <td>1.117481</td>\n",
              "      <td>-0.638821</td>\n",
              "      <td>-0.636661</td>\n",
              "      <td>-0.026946</td>\n",
              "      <td>0.430751</td>\n",
              "      <td>-0.890797</td>\n",
              "      <td>-0.066843</td>\n",
              "      <td>0.123326</td>\n",
              "      <td>-0.044318</td>\n",
              "      <td>0.721603</td>\n",
              "      <td>0.246874</td>\n",
              "      <td>-1.418097</td>\n",
              "      <td>-0.073750</td>\n",
              "      <td>-1.086791</td>\n",
              "      <td>-0.121525</td>\n",
              "      <td>0.554979</td>\n",
              "      <td>-2.241509</td>\n",
              "      <td>-1.591624</td>\n",
              "      <td>0.087217</td>\n",
              "      <td>-1.365929</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>670 rows × 512 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5253c9fe-0881-42d1-9814-7aeb1f8ab293')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5253c9fe-0881-42d1-9814-7aeb1f8ab293 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5253c9fe-0881-42d1-9814-7aeb1f8ab293');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         0         1         2    ...       509       510       511\n",
              "0   1.863567 -0.570675  2.186903  ... -0.376124  0.448598  1.668019\n",
              "1   1.335494  0.292490 -0.508044  ...  0.727233  1.154358  2.425046\n",
              "2   1.869617  0.700056  2.544178  ...  0.174274  0.524155  0.025221\n",
              "3   1.143558  0.006077 -0.493171  ...  0.562645  0.800046  1.888708\n",
              "4   0.222054  0.008657  0.506482  ... -1.591113  0.087331 -1.365646\n",
              "..       ...       ...       ...  ...       ...       ...       ...\n",
              "5   0.856003 -0.090863  2.167351  ... -0.022574 -0.419768  2.290327\n",
              "6   2.263805  0.194879  2.773061  ...  2.197751  1.442113  0.696673\n",
              "7   1.510298  1.078710  2.728060  ...  0.374264  0.934539 -0.042964\n",
              "8   0.137370  0.082786  0.450325  ... -1.549646  0.054569 -1.326485\n",
              "9   0.222346  0.008665  0.506922  ... -1.591624  0.087217 -1.365929\n",
              "\n",
              "[670 rows x 512 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('test_data_mlp.csv', index=False)"
      ],
      "metadata": {
        "id": "PIgFSHvoMbmX"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz8WzPq8B9KB"
      },
      "source": [
        "Reconstructed image from image vector generated from transformer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "hEh1xv-79icl"
      },
      "outputs": [],
      "source": [
        "# z = hidden_out.reshape(10, 32, 32)[2][None,...]\n",
        "# z = F.one_hot(z, num_classes=enc.vocab_size).permute(0, 3, 1, 2).float()\n",
        "\n",
        "# dec = dec.to(device)\n",
        "# x_stats = dec(z).float()\n",
        "# x_rec = unmap_pixels(torch.sigmoid(x_stats[:, :3]))\n",
        "# x_rec = T.ToPILImage(mode='RGB')(x_rec[0])\n",
        "\n",
        "# display_markdown('Reconstructed image:')\n",
        "# display(x_rec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyuoB7bOCFjT"
      },
      "source": [
        "Original Image:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "zXfwHieQBfwK"
      },
      "outputs": [],
      "source": [
        "# z = y.reshape(10, 32, 32)[2][None,...]\n",
        "# z = F.one_hot(z, num_classes=enc.vocab_size).permute(0, 3, 1, 2).float()\n",
        "\n",
        "# dec = dec.to(device)\n",
        "# x_stats = dec(z).float()\n",
        "# x_rec = unmap_pixels(torch.sigmoid(x_stats[:, :3]))\n",
        "# x_rec = T.ToPILImage(mode='RGB')(x_rec[0])\n",
        "\n",
        "# display_markdown('Reconstructed image:')\n",
        "# display(x_rec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y3u1ZuGChc2"
      },
      "source": [
        "Although work, but bad performance."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "transformer_generator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}